.. Copyright (C) ALbert Mietus; 2020, 2023

.. sidebar:: On this page
   :class: localtoc

   .. contents::
      :depth: 3
      :local:
      :backlinks: none

.. _startingBTDD:

****************************
Applying BDD & TDD in legacy
****************************

.. post:: 2023/05/07
   :tags: BDD, TDD, Modernize
   :category: opinion
   :location: Geldrop
   :language: en

   :reading-time: XXX

   As I described last week (in :ref:`introducingBTDD`), understanding the common goals of Behavior & Test Driven
   Development **and** defining your specific needs is the first and most critical step to start using this essential
   discipline.
   |BR|
   Whenever the goal is to use new tools, it is simple: purchase them, shop for some hands-on training, and you are
   done.

   Our ambition is different: we want to become *Agile* and *Lean*.
   |BR|
   Then, it depends on the starting point too. B&TDD in greenfield development is relatively simple: start writing your
   tests and code!

   However, starting with B&TDD in (Modern) Embedded Software can be more challenging due to the existing and often
   extensive codebase that was developed before the emergence of B&TDD.
   |BR|
   Then, the question ‘How to start?’ is more like *’How to get out of the waterfall?’*


=============
How to start?
=============

With millions of lines of existing code, a requirement such as ‘*Apply TDD (or/or BDD) everywhere*’ isn’t realistic.
One needs realistic goals as a point on the horizon and some derived ones for the short term. And one should
constantly measure whether you have reached them, and update the short-term goals.
|BR|
Sound familiar? That is essentially TDD!

A requirement like: ‘*For every iteration (sprint, release, ...), the test coverage should* **grow**’ is more realistic. And is
relatively easy to measure.
|BR|
I like to extend that requirement in two ways:

#. Such that is valid for all levels in the ‘V’, so for all units (unit tests), modules, and the system (acceptance
   tests)
#. That only automated tests count.

.. hint::

   I deliberately demand **more coverage** only, not that *new code* is developed with Behavior or Test Driven
   Development.
   |BR|
   As B&TDD is a simple implementation to grow the coverage, I expect that will happen. But when (in corner cases,
   somebody improves *old code*, that is acceptable too --even when that comes with new “not TDD” code.

   It’s unlikely that somebody, or a team, does --and stupid. But by defining the requirement in this way, it’s a
   lot easier to count.
   |BR|
   I value measuring progress over a strict definition.

Measure & show
==============

Just measuring does not promote improvement; Is ‘42’ good?
|BR|
It’s only usable measurement when it was ‘41’ last week, and we are on an upward path.

We need to show improvement. And so, we need to measure, store all values and display them in a graph. How? That isn’t
important. Possibly you can reuse the tools to show the sprint-burndown or the :ref:`BAV_graph`.
|BR|
I usually start with a big sheet of flip-over paper; it costs nothing and only 5 minutes each sprint to update
it. Remember: be lean is our chapter.


Count, count & graph!
---------------------

Many definitions  (and tools) exist to count coverage.  For a start, the exact measurement is not that
important. For now, a simple, quick (and simple) visualisation is more important than anything else.
|BR|
With a good toolsmith in the team, I would go for something simple as ‘grep & count’ functions in test and
production code and show the quotient (over time). Someday, that number should be (far) above 1.0. Probably, you will
start close to 0.0.

That number should be calculated per file (roughly unit-level), per directory (module level), and aggregated to system
level. Where one preferable should use requirement coverage, not code coverage. But again, keep it simple, give insight,
and don’t fall into the pitfall of theoretical wisdom.
|BR|
When available, simply add a graph showing the ratio number-of-acceptance-tests to the number-of-requirements,
again over time. Add it, don’t replace it --trust your developers. And coach them to use the right graph.

Because it is simple, developers can influence it and are motivated to add more tests. And write testable code.
|BR|
That is the goal, so even when the counting tool is only an approximation, it will do!

Clean Code is short-code
------------------------

New functions should be implemented in a “clean, testable & maintainable” style code. Which suggests small functions.

Therefore I would also like to add a simple measurement as the “line-count pro function”, visualised in buckets. For
example, the percentage of functions that are less (or equal to) 5 lines, 10, 24, 63 lines, etc. Over time the smaller
buckets should be dominant.

Focus on new & updated functions
--------------------------------

Introducing TDD in an existing project is never perfect. Temporally, one should accept that existing/old code will have
no or very limited test coverage. Some ancient-styled, never-updated code will effectively never becomes better -- on
the other hand, when there is no need to update it, and it is *field proven correct*, there is no business value in
making it better.

That does not apply to new units, they do not have a track record of correctness, and there is no reason to not write
that code in a clean, testable way. And so, the team should be motivated to embrace TDD there.

This also applies to existing code, that needs to be updated.
|BR|
As it is changing the old code, the  rule “don’t fix when it ain’t broken” is invalid; there is a risk of mistakes. The cost
of testing (and fixing bugs) have to be taken -- even when that involves (manual) testing at the system level. So:
apply TTD (and BDD) to that part. Temporally, one can focus the test on new requirements and the “high-risk” changes.

.. tip::

   A pragmatic approach is to minimise the interface between the *old* and *new* code: don’t add many lines to an
   existing function. Instead write some (small, clean, testable) new functions (with TDD), and add only a few lines to
   call them in the existing code.

   That also prevents combining code styles in one file.

===============
Where to start?
===============

In many organisations, starting with B&TDD is mostly waiting on others.
|BR|



Developer versus Team
=====================

TDD and BDD act on different levels. TDD is typically at the bottom of the *’V’*; BDD is more at the system (or
acceptance) level.
|BR|
However, that is often confusing for new adopters.

Therefore I often use a more pragmatic distinguishment: Individual Developer versus (scrum)Team.
|BR|
A single developer can act following  TDD. (S)he writes code, tests, and production code and switches between them
every minute. As TDD is more productive, hardly anyone will notice it when somebody “secretly” adopts TDD. No
extra tools or frameworks are essential.

That is hardly possible with BDD, as this is at the team level. A developer can’t run an acceptance test without the
assistance of a tester designer.
|BR|
Despite this, a single team can embrace BDD -- even when others don’t

This is valid for all levels: the larger the part that is worked on, the more commitment needs to be able to run those
ATSes.


1. Product-quality improvement: in short: better code and better products

   - TDD focuses more on the *abilities* of code: readability, testability, **maintainability**, etc.
   - BDD is more product-level: **“Does it do what is specified?”**, and “Are the specification correct?”

2. Process optimisation: reduce the cost of the development cycle.

   - The faster a bug is signaled, the cheaper is to repair.
   - TDD also provides an *‘exit strategy’*; an often forgotten “side-effect” increasing velocity.


