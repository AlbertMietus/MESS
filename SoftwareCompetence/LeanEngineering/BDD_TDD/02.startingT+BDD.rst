.. Copyright (C) ALbert Mietus; 2020, 2023

.. sidebar:: On this page
   :class: localtoc

   .. contents::
      :depth: 3
      :local:
      :backlinks: none

.. _startingBTDD:

**************************
Applying BDD & TDD (DRAFT)
**************************

.. post:: 2023/05/07
   :tags: BDD, TDD, Modernize
   :category: opinion
   :location: Geldrop
   :language: en

   :reading-time: XXX

   As I described last week (in :ref:`introducingBTDD`), understanding the common goals of Behavior & Test Driven
   Development **and** defining your specific needs is the first and most critical step to start using this essential
   discipline.
   |BR|
   Whenever the goal is to use new tools, it is simple: purchase them, shop for some hands-on training, and you are
   done.

   Our ambition is different: we want to become *Agile* and *Lean*.
   |BR|
   Then, it depends on the starting point too. B&TDD in greenfield development is relatively simple: start writing your
   tests and code!

   However, starting with B&DD in (Modern) Embedded Software can be more challenging due to the existing and often
   extensive codebase that was developed before the emergence of B&DD.
   |BR|
   Then, the question ‘How to start?’ is more like *’How to get out of the waterfall?’*


=============
How to start?
=============

With millions of lines of existing code, a requirement such as ‘*Apply TDD (or/or BDD) everywhere*’ isn’t realistic.
One needs realistic goals, both as points on the horizon and for the short term.  And one should constantly measure
whether you have reached them.
|BR|
Sound familiar? That is essentially TDD!

A requirement like: ‘*For every iteration (sprint, release, ...), the test coverage should grow*’ is more realistic. And is
relatively easy to measure.
|BR|
I like to extend that requirement, in two ways:

#. Such that is valid for all levels in the ‘V’, so for all units (unit tests), modules, and the system (acceptance
   tests)
#. That only automated tests count.

.. hint::

   I deliberately demand *more* coverage only, not that *new code* is developed with Behavior or Test Driven
   Development.
   |BR|
   That is the easiest implementation, and so I expect that. But when *old code* is improved that is acceptable too --even
   when that comes with new “untested” code.

   It’s unlikely that somebody, or a team does so,  --and stupid. But by defining the requirement in this way, it’s a
   lot easier to count.
   |BR|
   And measuring is even more important.

Add the measurements
====================

Just measuring does not promote improvement; Is ‘42’ good?
|BR|
It’s only usable measurement when it was ‘41’ last week, and we are on an upward path.

We need to show improvement. And so, we need to measure, store all values and show them in a graph. How? That isn’t
important. Possibly you can reuse the tools to show the sprint-burndown or the :ref:`BAV_graph`.
|BR|
I usually start with a big sheet of flip-over paper; it cost nothing and only 5 minutes each sprint to update
it. Remember: be lean in our chapter.


Count, count & graph
--------------------

Many definitions  (and tools) exist on “how to count coverage”.  For a start, the exact measurement is not that
important. For now, a simple, quick (and simple) visualisation is more important than anything else.

With a good toolsmith in the team, I would go for something simple as ‘grep & count’ functions in test and
production code and show the quotient (over time). Someday, that number should be (far) above 1.0. Probably, you will
start close to 0.0.
|BR|
That number should be calculated per file (roughly unit-level), per directory (module level), and aggregated to system
level. For that level, you probably like to count acceptance, not technical tests. When available, you can also display
the ratio number-of-acceptance-tests to the number-of-requirements.

Because it is simple, developers can influence it and are motivated to add more tests.
|BR|
That is the goal, so even when the counting tool is only an approximation, it will do.

Clean Code is short-code
------------------------

New functions should be implemented in a “clean style” so testable code. Which suggests small functions.

Therefore I would also like to add a simple measurement as the “line-count pro function”. And visualize that in buckets: the
percentage of functions that are less (or equal to) 5 lines, 10, 24, 63 lines, etc. Over time the smaller buckets should
be dominant.

Focus on new & updated functions
--------------------------------

Introducing TDD in an existing project is never perfect. Temporally, one should accept that existing/old code will have
no or very limited test coverage. Some ancient-styled, never-updated code will effectively never becomes better -- on
the other hand, when there is no need to update it, and it is *field proven correct*, there is no business value in
making it better.

That does not apply to new units, they do not have a track record of correctness, and there is no reason to not write
that code in a clean, testable way. And so, the team should be motivated to embrace TDD there.

This also applies to existing code, that needs to be updated.
|BR|
As it is changing the old code, the  rule “don’t fix when it ain’t broken” is invalid; there is a risk of mistakes. The cost
of testing (and fixing bugs) have to be taken -- even when that involves (manual) testing at the system level. So:
apply TTD (and BDD) to that part. Temporally, one can focus the test on new requirements and the “high-risk” changes.

.. tip::

   A pragmatic approach is to minimise the interface between the *old* and *new* code: don’t add many lines to an
   existing function. Instead write some (small, clean, testable) new functions (with TDD), and add only a few lines to
   call them in the existing code.

   That also prevents combining code styles in one file

===============
Where to start?
===============

In many organisations, starting with B&TDD is mostly waiting on others.
|BR|



Developer versus Team
=====================

TDD and BDD act on different levels. TDD is typically at the bottom of the *’V’*; BDD is more at the system (or
acceptance) level.
|BR|
However, that is often confusing for new adopters.

Therefore I often use a more pragmatic distinguishment: Individual Developer versus (scrum)Team.
|BR|
A single developer can act following  TDD. (S)he writes code, tests, and production code and switches between them
every minute. As TDD is more productive, hardly anyone will notice it when somebody “secretly” adopts TDD. No
extra tools or frameworks are essential.

That is hardly possible with BDD, as this is at the team level. A developer can’t run an acceptance test without the
assistance of a tester designer.
|BR|
Despite this, a single team can embrace BDD -- even when others don’t

This is valid for all levels: the larger the part that is worked on, the more commitment needs to be able to run those
ATSes.


1. Product-quality improvement: in short: better code and better products

   - TDD focuses more on the *abilities* of code: readability, testability, **maintainability**, etc.
   - BDD is more product-level: **“Does it do what is specified?”**, and “Are the specification correct?”

2. Process optimisation: reduce the cost of the development cycle.

   - The faster a bug is signaled, the cheaper is to repair.
   - TDD also provides an *‘exit strategy’*; an often forgotten “side-effect” increasing velocity.


